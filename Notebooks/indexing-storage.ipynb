{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"dangvantuan/sentence-camembert-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00716ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant = QdrantClient(path=\"../qdrant_data\") #Switched from using qdrant 'production mode' to 'embedded mode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a923db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import hashlib\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
    "\n",
    "# Helper function to convert string IDs to valid UUID-compatible IDs\n",
    "def string_to_uuid(string_id):\n",
    "    \"\"\"Convert a string to a deterministic UUID by hashing it\"\"\"\n",
    "    # Create MD5 hash of the string\n",
    "    hash_object = hashlib.md5(string_id.encode())\n",
    "    # Convert to hex\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "    # Create a UUID from the hex string\n",
    "    return uuid.UUID(hex_dig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef4a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('output_chunks.json', 'r', encoding='utf-8') as f:\n",
    "        documents = json.load(f)\n",
    "    print(f\"✓ Loaded {len(documents)} documents from output_chunks.json\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: output_chunks.json file not found!\")\n",
    "    sys.exit(1)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: Invalid JSON format in output_chunks.json!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 5. Create a collection\n",
    "collection_name = \"Auditron_legal_chunks\"\n",
    "print(f\"Creating collection '{collection_name}'...\")\n",
    "qdrant.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=model.get_sentence_embedding_dimension(), distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# 6. Process the documents\n",
    "print(\"Processing documents...\")\n",
    "total_chunks = sum(len(doc.get(\"chunks\", [])) for doc in documents)\n",
    "batch_size = 50\n",
    "processed_count = 0\n",
    "error_count = 0\n",
    "batch_points = []\n",
    "id_mapping = {}  # To store mapping between original IDs and UUID IDs\n",
    "\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    print(f\"Processing document {doc_idx+1}/{len(documents)}\")\n",
    "    chunks = doc.get(\"chunks\", [])\n",
    "    \n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        try:\n",
    "            # Extract text and ID\n",
    "            text = chunk.get(\"text\", \"\")\n",
    "            original_id = chunk.get(\"chunk_id\", f\"unknown_{doc_idx}_{chunk_idx}\")\n",
    "            \n",
    "            if not text.strip():  # Skip empty chunks\n",
    "                print(f\"Warning: Empty text in chunk {original_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Clean and truncate text if necessary to avoid index errors\n",
    "            # Some models have maximum input length limitations\n",
    "            max_text_length = 512  # Adjust based on your model's limitations\n",
    "            text = text.strip()[:max_text_length]\n",
    "            \n",
    "            # Convert string ID to UUID\n",
    "            point_id = string_to_uuid(original_id)\n",
    "            \n",
    "            # Save mapping\n",
    "            id_mapping[str(point_id)] = original_id\n",
    "            \n",
    "            # Generate embedding with error handling\n",
    "            try:\n",
    "                embedding = model.encode(text, show_progress_bar=False)\n",
    "            except Exception as embed_error:\n",
    "                print(f\"Embedding error for chunk {original_id}: {str(embed_error)}\")\n",
    "                # Try with a shorter text if it might be a length issue\n",
    "                if len(text) > 200:\n",
    "                    try:\n",
    "                        shorter_text = text[:200]\n",
    "                        print(f\"Retrying with shorter text for {original_id}\")\n",
    "                        embedding = model.encode(shorter_text, show_progress_bar=False)\n",
    "                    except Exception as retry_error:\n",
    "                        print(f\"Still failed with shorter text: {str(retry_error)}\")\n",
    "                        error_count += 1\n",
    "                        continue\n",
    "                else:\n",
    "                    error_count += 1\n",
    "                    continue\n",
    "            \n",
    "            # Create point with UUID\n",
    "            point = PointStruct(\n",
    "                id=str(point_id),\n",
    "                vector=embedding.tolist(),\n",
    "                payload={\n",
    "                    \"text\": text,\n",
    "                    \"original_id\": original_id,  # Keep original ID in payload\n",
    "                    \"structures\": chunk.get(\"structures\", []),\n",
    "                    \"document_path\": chunk.get(\"document_path\", []),\n",
    "                    \"metadata\": chunk.get(\"metadata\", {})\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Add to batch\n",
    "            batch_points.append(point)\n",
    "            processed_count += 1\n",
    "            \n",
    "            # If batch is full, upload to Qdrant\n",
    "            if len(batch_points) >= batch_size:\n",
    "                qdrant.upsert(\n",
    "                    collection_name=collection_name,\n",
    "                    points=batch_points,\n",
    "                )\n",
    "                print(f\"Uploaded batch: {processed_count}/{total_chunks} chunks ({error_count} errors so far)\")\n",
    "                batch_points = []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {original_id}: {str(e)}\")\n",
    "            error_count += 1\n",
    "\n",
    "# Upload any remaining points\n",
    "if batch_points:\n",
    "    qdrant.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=batch_points,\n",
    "    )\n",
    "    print(f\"Uploaded final batch: {processed_count}/{total_chunks} chunks\")\n",
    "\n",
    "# Save ID mapping for reference (optional)\n",
    "try:\n",
    "    with open('id_mapping.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(id_mapping, f, indent=2)\n",
    "    print(\"✓ Saved ID mapping to id_mapping.json\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not save ID mapping: {str(e)}\")\n",
    "\n",
    "print(f\"✅ Successfully processed {processed_count}/{total_chunks} chunks into Qdrant collection '{collection_name}'!\")\n",
    "print(f\"Total errors encountered: {error_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6964aeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auditron_venv",
   "language": "python",
   "name": "auditron_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
