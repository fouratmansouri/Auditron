{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfae42b",
   "metadata": {},
   "source": [
    "### About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2604dba9",
   "metadata": {},
   "source": [
    "This notebook uses the following frameworks\n",
    "* Langchain\n",
    "\n",
    "* Langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc67d5",
   "metadata": {},
   "source": [
    "### 1. Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e14b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain_community langchain-qdrant langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba2f29b",
   "metadata": {},
   "source": [
    "### 2. Local models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94575916",
   "metadata": {},
   "source": [
    "Loading the embedding model \"sentence-camembert-large\" from hugging face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482de071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\foura\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name dangvantuan/sentence-camembert-large. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"dangvantuan/sentence-camembert-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272224fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HuggingFaceEmbeddings' object has no attribute 'get_sentence_embedding_dimension'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embeddings\u001b[38;5;241m.\u001b[39mget_sentence_embedding_dimension()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:892\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 892\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HuggingFaceEmbeddings' object has no attribute 'get_sentence_embedding_dimension'"
     ]
    }
   ],
   "source": [
    "embeddings.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dddf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "local_llm = \"mistral:7b-instruct\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "llm_json_mode = ChatOllama(model=local_llm, temperature=0, format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b28bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06eb40",
   "metadata": {},
   "source": [
    "### 3. Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42238797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a15f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import hashlib\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
    "\n",
    "# Helper function to convert string IDs to valid UUID-compatible IDs\n",
    "def string_to_uuid(string_id):\n",
    "    \"\"\"Convert a string to a deterministic UUID by hashing it\"\"\"\n",
    "    # Create MD5 hash of the string\n",
    "    hash_object = hashlib.md5(string_id.encode())\n",
    "    # Convert to hex\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "    # Create a UUID from the hex string\n",
    "    return uuid.UUID(hex_dig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc03e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load your JSON file\n",
    "try:\n",
    "    with open('output_chunks.json', 'r', encoding='utf-8') as f:\n",
    "        documents = json.load(f)\n",
    "    print(f\"✓ Loaded {len(documents)} documents from output_chunks.json\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: output_chunks.json file not found!\")\n",
    "    sys.exit(1)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: Invalid JSON format in output_chunks.json!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 5. Create a collection\n",
    "collection_name = \"Auditron_legal_chunks\"\n",
    "print(f\"Creating collection '{collection_name}'...\")\n",
    "qdrant.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=model.get_sentence_embedding_dimension(), distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# 6. Process the documents\n",
    "print(\"Processing documents...\")\n",
    "total_chunks = sum(len(doc.get(\"chunks\", [])) for doc in documents)\n",
    "batch_size = 50\n",
    "processed_count = 0\n",
    "error_count = 0\n",
    "batch_points = []\n",
    "id_mapping = {}  # To store mapping between original IDs and UUID IDs\n",
    "\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    print(f\"Processing document {doc_idx+1}/{len(documents)}\")\n",
    "    chunks = doc.get(\"chunks\", [])\n",
    "    \n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        try:\n",
    "            # Extract text and ID\n",
    "            text = chunk.get(\"text\", \"\")\n",
    "            original_id = chunk.get(\"chunk_id\", f\"unknown_{doc_idx}_{chunk_idx}\")\n",
    "            \n",
    "            if not text.strip():  # Skip empty chunks\n",
    "                print(f\"Warning: Empty text in chunk {original_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Clean and truncate text if necessary to avoid index errors\n",
    "            # Some models have maximum input length limitations\n",
    "            max_text_length = 512  # Adjust based on your model's limitations\n",
    "            text = text.strip()[:max_text_length]\n",
    "            \n",
    "            # Convert string ID to UUID\n",
    "            point_id = string_to_uuid(original_id)\n",
    "            \n",
    "            # Save mapping\n",
    "            id_mapping[str(point_id)] = original_id\n",
    "            \n",
    "            # Generate embedding with error handling\n",
    "            try:\n",
    "                embedding = model.encode(text, show_progress_bar=False)\n",
    "            except Exception as embed_error:\n",
    "                print(f\"Embedding error for chunk {original_id}: {str(embed_error)}\")\n",
    "                # Try with a shorter text if it might be a length issue\n",
    "                if len(text) > 200:\n",
    "                    try:\n",
    "                        shorter_text = text[:200]\n",
    "                        print(f\"Retrying with shorter text for {original_id}\")\n",
    "                        embedding = model.encode(shorter_text, show_progress_bar=False)\n",
    "                    except Exception as retry_error:\n",
    "                        print(f\"Still failed with shorter text: {str(retry_error)}\")\n",
    "                        error_count += 1\n",
    "                        continue\n",
    "                else:\n",
    "                    error_count += 1\n",
    "                    continue\n",
    "            \n",
    "            # Create point with UUID\n",
    "            point = PointStruct(\n",
    "                id=str(point_id),\n",
    "                vector=embedding.tolist(),\n",
    "                payload={\n",
    "                    \"text\": text,\n",
    "                    \"original_id\": original_id,  # Keep original ID in payload\n",
    "                    \"structures\": chunk.get(\"structures\", []),\n",
    "                    \"document_path\": chunk.get(\"document_path\", []),\n",
    "                    \"metadata\": chunk.get(\"metadata\", {})\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Add to batch\n",
    "            batch_points.append(point)\n",
    "            processed_count += 1\n",
    "            \n",
    "            # If batch is full, upload to Qdrant\n",
    "            if len(batch_points) >= batch_size:\n",
    "                qdrant.upsert(\n",
    "                    collection_name=collection_name,\n",
    "                    points=batch_points,\n",
    "                )\n",
    "                print(f\"Uploaded batch: {processed_count}/{total_chunks} chunks ({error_count} errors so far)\")\n",
    "                batch_points = []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {original_id}: {str(e)}\")\n",
    "            error_count += 1\n",
    "\n",
    "# Upload any remaining points\n",
    "if batch_points:\n",
    "    qdrant.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=batch_points,\n",
    "    )\n",
    "    print(f\"Uploaded final batch: {processed_count}/{total_chunks} chunks\")\n",
    "\n",
    "# Save ID mapping for reference (optional)\n",
    "try:\n",
    "    with open('id_mapping.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(id_mapping, f, indent=2)\n",
    "    print(\"✓ Saved ID mapping to id_mapping.json\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not save ID mapping: {str(e)}\")\n",
    "\n",
    "print(f\"✅ Successfully processed {processed_count}/{total_chunks} chunks into Qdrant collection '{collection_name}'!\")\n",
    "print(f\"Total errors encountered: {error_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa01f5b",
   "metadata": {},
   "source": [
    "### 4. Retrieving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c868e460",
   "metadata": {},
   "source": [
    "**4.1 Semantic search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import SearchParams\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "# 3. Create the vector store with LangChain\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrant,\n",
    "    collection_name=\"Auditron_legal_chunks\",  # Your collection name\n",
    "    content_payload_key=\"text\", \n",
    "    embedding=embeddings,\n",
    ")\n",
    "#    search_params=SearchParams(hnsw_ef=128)  # Your search params\n",
    "# 4. Create the retriever from the vector store\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 5. Use the retriever\n",
    "query = \"Quel est le nouveau taux unifié de retenue à la source applicable aux loyers, rémunérations non commerciales, honoraires et commissions en Tunisie depuis l'adoption de la loi N° 2020-46 du 23 décembre 2020?\"\n",
    "documents = retriever.invoke(query)\n",
    "\n",
    "# The retrieved documents will include content and metadata\n",
    "for doc in documents:\n",
    "    print(doc.page_content)  # Access the content\n",
    "    print(doc.metadata)      # Access the metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7780c0",
   "metadata": {},
   "source": [
    "### Document re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d19070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "### Retrieval Grader\n",
    "\n",
    "# Doc grader instructions\n",
    "doc_grader_instructions = \"\"\"Vous êtes un modèle chargé d’évaluer la pertinence d’un document récupéré par rapport à une question utilisateur.\n",
    "\n",
    "Si le document contient des mots-clés ou un sens sémantique lié à la question, considérez-le comme pertinent.\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "doc_grader_prompt = \"\"\"Voici le document récupéré : \\n\\n {document} \\n\\n Voici la question de l'utilisateur : \\n\\n {question}.\n",
    "\n",
    "Évaluez soigneusement et objectivement si le document contient au moins une information pertinente en lien avec la question.\n",
    "\n",
    "Retournez un JSON avec une clé unique, binary_score, qui sera 'oui' ou 'non' pour indiquer si le document contient au moins une information pertinente pour la question.\"\"\"\n",
    "# Test\n",
    "question = \"Quel est le nouveau taux unifié de retenue à la source applicable aux loyers, rémunérations non commerciales, honoraires et commissions en Tunisie depuis l'adoption de la loi N° 2020-46 du 23 décembre 2020?\"\n",
    "\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[0].page_content\n",
    "\n",
    "doc_grader_prompt_formatted = doc_grader_prompt.format(\n",
    "    document=doc_txt, question=question\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=doc_grader_instructions)]\n",
    "    + [HumanMessage(content=doc_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e749dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[2].page_content\n",
    "\n",
    "doc_grader_prompt_formatted = doc_grader_prompt.format(\n",
    "    document=doc_txt, question=question\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=doc_grader_instructions)]\n",
    "    + [HumanMessage(content=doc_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbde3f0",
   "metadata": {},
   "source": [
    "**4.2 Implementig Hybrid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever  # Changed import location\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Load all points from Qdrant\n",
    "response = qdrant.scroll(\n",
    "    collection_name=\"Auditron_legal_chunks\",\n",
    "    limit=10_000,  # Increase if needed, Qdrant supports pagination\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "# Convert Qdrant points to LangChain Documents\n",
    "all_documents = []\n",
    "for point in response[0]:  # response = (points, next_page_offset)\n",
    "    payload = point.payload\n",
    "    content = payload.get(\"text\", \"\")\n",
    "    metadata = {k: v for k, v in payload.items() if k != \"text\"}\n",
    "    all_documents.append(Document(page_content=content, metadata=metadata))\n",
    "    # Initialize the BM25 retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(all_documents)\n",
    "bm25_retriever.k = 3  # Retrieve top 5 results\n",
    "\n",
    "# Create the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, retriever], \n",
    "    weights=[0.4, 0.6]  # You can adjust these weights based on performance\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e3a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query\n",
    "query = \"Quel est le taux de retenue à la source sur les dividendes distribués par des sociétés tunisiennes à des personnes non résidentes, et comment une convention de non-double imposition peut-elle modifier ce taux pour les bénéficiaires d’une telle convention ?\"\n",
    "# Use the ensemble retriever\n",
    "documents = ensemble_retriever.invoke(query)\n",
    "\n",
    "# The retrieved documents will include content and metadata\n",
    "for doc in documents:\n",
    "    print(doc.page_content)  # Access the content\n",
    "    print(doc.metadata)      # Access the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = ensemble_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd7df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9396b",
   "metadata": {},
   "source": [
    "**4.3 Relevancy threshold** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe5c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import SearchParams\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create the vector store with LangChain\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=qdrant,\n",
    "    collection_name=\"Auditron_legal_chunks\",  # Your collection name\n",
    "    content_payload_key=\"text\", \n",
    "    embedding=embeddings,\n",
    ")\n",
    "#    search_params=SearchParams(hnsw_ef=128)  # Your search params\n",
    "\n",
    "# 4. Create the retriever from the vector store\n",
    "qdrant_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"score_threshold\": 0.4\n",
    "    }\n",
    ")\n",
    "\n",
    "# Load all points from Qdrant\n",
    "response = qdrant.scroll(\n",
    "    collection_name=\"Auditron_legal_chunks\",\n",
    "    limit=10_000,  # Increase if needed, Qdrant supports pagination\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "all_documents = []\n",
    "for point in response[0]:  # response = (points, next_page_offset)\n",
    "    payload = point.payload\n",
    "    content = payload.get(\"text\", \"\")\n",
    "    metadata = {k: v for k, v in payload.items() if k != \"text\"}\n",
    "    all_documents.append(Document(page_content=content, metadata=metadata))\n",
    "    \n",
    "# Set up your retrievers with the with_score parameter\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    all_documents,\n",
    "    k=5,\n",
    "    with_score=True  # This returns scores with documents\n",
    ")\n",
    "\n",
    "# Combine them\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, qdrant_retriever], \n",
    "    weights=[0.4, 0.6]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_threshold(query):\n",
    "    docs = ensemble_retriever.invoke(query)\n",
    "    for doc in docs:\n",
    "        print(f\"Score: {doc.metadata.get('score', 'N/A')}, Content: {doc.page_content}\")\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "results = retrieve_with_threshold(\"Quel est le taux de la retenue à la source sur les dividendes versés à une personne morale résidente ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9758ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a841cf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name dangvantuan/sentence-camembert-large. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 [Score: 0.658]\n",
      "RETENUES A LA SOURCE ARTICLE 52 :\n",
      "\n",
      "L'impôt sur le revenu et l'impôt sur les sociétés font l'objet d'une retenue à la source aux taux suivants :...\n",
      "\n",
      "Document 2 [Score: 0.662]\n",
      "b- Les retenues à la source L’impôt sur le revenu et l’impôt sur les sociétés font l’objet d’une retenue à la source, et ce, pour les montants qui sont dans le champ d’application de ladite retenue et payés par les personnes soumises à l’obligation d’effectuer la retenue à la source....\n",
      "\n",
      "Document 3 [Score: 0.660]\n",
      "Pour la détermination du prix (1) Ce taux s’applique aux revenus distribués à partir du 01/01/2018 et demeurent exonérés de l’impôt sur les bénéfices distribués les opérations de distribution de bénéfices à partir des fonds propres figurant au bilan de la société distributrice au 31 décembre 2013, à...\n",
      "\n",
      "Document 4 [Score: 0.651]\n",
      "L’impôt sur le revenu dû au titre de la plus-value Sous réserve des exonérations prévues par la législation en vigueur, la plus- value réalisée par les personnes physiques et provenant de la cession des titres non rattachés à un bilan et des droits y relatifs, est soumise à l’impôt sur le revenu sel...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foura\\AppData\\Local\\Temp\\ipykernel_23092\\1034766933.py:23: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = self.vectorstore.client.search(\n"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from typing import List, Any\n",
    "from pydantic import Field\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# 1. Updated Qdrant retriever with explicit embeddings\n",
    "class QdrantScoreRetriever(BaseRetriever):\n",
    "    vectorstore: QdrantVectorStore = Field(...)\n",
    "    embeddings: Embeddings = Field(...)  # Explicit embeddings field\n",
    "    k: int = Field(default=5)\n",
    "    score_threshold: float = Field(default=0.4)\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        # Get embedding using the explicit embeddings model\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        \n",
    "        # Search Qdrant with score threshold\n",
    "        results = self.vectorstore.client.search(\n",
    "            collection_name=self.vectorstore.collection_name,\n",
    "            query_vector=query_embedding,\n",
    "            limit=self.k,\n",
    "            score_threshold=self.score_threshold,\n",
    "            with_payload=True\n",
    "        )\n",
    "\n",
    "        documents = []\n",
    "        for result in results:\n",
    "            content = result.payload.get(\"text\", \"\")\n",
    "            metadata = {k: v for k, v in result.payload.items() if k != \"text\"}\n",
    "            metadata[\"score\"] = result.score  # Store similarity score\n",
    "            documents.append(Document(\n",
    "                page_content=content,\n",
    "                metadata=metadata\n",
    "            ))\n",
    "        \n",
    "        return documents\n",
    "\n",
    "# 2. Initialize components\n",
    "qdrant = qdrant = QdrantClient(url=\"http://localhost:6333\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"dangvantuan/sentence-camembert-large\")\n",
    "\n",
    "# Create vector store\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=qdrant,\n",
    "    collection_name=\"Auditron_legal_chunks\",\n",
    "    content_payload_key=\"text\",\n",
    "    embedding=embeddings,  # This might not be needed depending on your Qdrant setup\n",
    ")\n",
    "\n",
    "# 3. Create Qdrant retriever with explicit embeddings\n",
    "qdrant_retriever = QdrantScoreRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    embeddings=embeddings,  # Pass embeddings explicitly\n",
    "    k=5,\n",
    "    score_threshold=0.4\n",
    ")\n",
    "\n",
    "# Load BM25 documents\n",
    "response = qdrant.scroll(\n",
    "    collection_name=\"Auditron_legal_chunks\",\n",
    "    limit=10_000,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "all_documents = [\n",
    "    Document(\n",
    "        page_content=point.payload.get(\"text\", \"\"),\n",
    "        metadata={k: v for k, v in point.payload.items() if k != \"text\"}\n",
    "    )\n",
    "    for point in response[0]\n",
    "]\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    all_documents,\n",
    "    k=5,\n",
    "    with_score=True\n",
    ")\n",
    "\n",
    "# 4. Create ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, qdrant_retriever],\n",
    "    weights=[0.4, 0.6]\n",
    ")\n",
    "\n",
    "# 5. Search function with threshold\n",
    "def retrieve_with_threshold(query: str, threshold: float = 0.4) -> List[Document]:\n",
    "    \"\"\"Retrieve documents with combined score above threshold\"\"\"\n",
    "    docs = ensemble_retriever.invoke(query)\n",
    "    \n",
    "    # Filter documents by combined score\n",
    "    filtered_docs = [\n",
    "        doc for doc in docs\n",
    "        if doc.metadata.get(\"score\", 0) >= threshold\n",
    "    ]\n",
    "    \n",
    "    # Print results\n",
    "    for i, doc in enumerate(filtered_docs, 1):\n",
    "        print(f\"Document {i} [Score: {doc.metadata['score']:.3f}]\")\n",
    "        print(doc.page_content[:300] + \"...\\n\")\n",
    "    \n",
    "    return filtered_docs\n",
    "\n",
    "# 6. Execute the search\n",
    "results = retrieve_with_threshold(\n",
    "    \"Quel est le taux de la retenue à la source sur les dividendes versés à une personne morale résidente ?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3e18a2",
   "metadata": {},
   "source": [
    "### 5. Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc2362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate\n",
    "\n",
    "# Prompt\n",
    "rag_prompt = \"\"\"Vous êtes un assistant pour des tâches de question-réponse.\n",
    "\n",
    "Voici le contexte à utiliser pour répondre à la question :\n",
    "\n",
    "{context}\n",
    "\n",
    "Réfléchissez soigneusement au contexte ci-dessus.\n",
    "\n",
    "Maintenant, examinez la question de l'utilisateur :\n",
    "\n",
    "{question}\n",
    "\n",
    "Fournissez une réponse à cette question en utilisant uniquement le contexte ci-dessus.\n",
    "\n",
    "Utilisez un maximum de trois phrases et gardez la réponse concise.\n",
    "\n",
    "Réponse :\"\"\"\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Test\n",
    "query = '''TEJ'''\n",
    "docs = ensemble_retriever.invoke(query)\n",
    "docs_txt = format_docs(docs)\n",
    "rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=query)\n",
    "generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "print(generation.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d682cc",
   "metadata": {},
   "source": [
    "Hallucination grader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8372b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "# Hallucination grader instructions\n",
    "hallucination_grader_instructions = \"\"\"\n",
    "\n",
    "Vous êtes un enseignant en train de corriger un quiz.\n",
    "\n",
    "Vous recevrez des FAITS et une RÉPONSE D'ÉLÈVE.\n",
    "\n",
    "Voici les critères de notation à suivre :\n",
    "\n",
    "(1) Assurez-vous que la RÉPONSE DE L'ÉLÈVE est bien fondée sur les FAITS.\n",
    "\n",
    "(2) Assurez-vous que la RÉPONSE DE L'ÉLÈVE ne contient pas d'informations « hallucinées » qui sortent du cadre des FAITS.\n",
    "\n",
    "Note :\n",
    "\n",
    "Une note de oui signifie que la réponse de l'élève respecte tous les critères. C’est la note la plus élevée (meilleure).\n",
    "\n",
    "Une note de non signifie que la réponse de l'élève ne respecte pas tous les critères. C’est la note la plus basse que vous pouvez attribuer.\n",
    "\n",
    "Expliquez votre raisonnement étape par étape afin de garantir la justesse de votre raisonnement et de votre conclusion.\n",
    "\n",
    "Évitez d’énoncer directement la bonne réponse dès le départ.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Grader prompt\n",
    "hallucination_grader_prompt = \"\"\"FAITS : \\n\\n {documents} \\n\\n RÉPONSE DE L'ÉLÈVE : {generation}.\n",
    "\n",
    "Retournez un JSON avec deux clés :  \n",
    "- binary_score : une valeur 'oui' ou 'non' indiquant si la RÉPONSE DE L'ÉLÈVE est bien fondée sur les FAITS.  \n",
    "- explanation : une explication justifiant la note attribuée.\n",
    "\"\"\"\n",
    "\n",
    "# Test using documents and generation from above\n",
    "hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(\n",
    "    documents=docs_txt, generation=generation.content\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=hallucination_grader_instructions)]\n",
    "    + [HumanMessage(content=hallucination_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46427e26",
   "metadata": {},
   "source": [
    "Answer grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Answer Grader\n",
    "\n",
    "# Answer grader instructions\n",
    "answer_grader_instructions = \"\"\"Vous êtes un enseignant en train de corriger un quiz.\n",
    "\n",
    "Vous recevrez une QUESTION et une RÉPONSE D'ÉLÈVE.\n",
    "\n",
    "Voici les critères de notation à suivre :\n",
    "\n",
    "(1) La RÉPONSE DE L'ÉLÈVE aide à répondre à la QUESTION.\n",
    "\n",
    "Note :\n",
    "\n",
    "Une note de oui signifie que la réponse de l'élève respecte tous les critères. C’est la note la plus élevée (meilleure).\n",
    "\n",
    "L’élève peut recevoir une note de oui même si la réponse contient des informations supplémentaires qui ne sont pas explicitement demandées dans la question.\n",
    "\n",
    "Une note de non signifie que la réponse de l'élève ne respecte pas tous les critères. C’est la note la plus basse que vous pouvez attribuer.\n",
    "\n",
    "Expliquez votre raisonnement étape par étape afin de garantir la justesse de votre raisonnement et de votre conclusion.\n",
    "\n",
    "Évitez d’énoncer directement la bonne réponse dès le départ.\n",
    "\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "answer_grader_prompt = \"\"\"QUESTION : \\n\\n {question} \\n\\n RÉPONSE DE L'ÉLÈVE : {generation}.\n",
    "\n",
    "Retournez un JSON avec deux clés :  \n",
    "- binary_score : une valeur 'oui' ou 'non' indiquant si la RÉPONSE DE L'ÉLÈVE respecte les critères.  \n",
    "- explanation : une explication justifiant la note attribuée.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Test\n",
    "answer = generation.content\n",
    "\n",
    "# Test using question and generation from above\n",
    "answer_grader_prompt_formatted = answer_grader_prompt.format(\n",
    "    question=question, generation=answer\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=answer_grader_instructions)]\n",
    "    + [HumanMessage(content=answer_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d410f",
   "metadata": {},
   "source": [
    "### 6. ChatAgent with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01b167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auditron_venv",
   "language": "python",
   "name": "auditron_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
