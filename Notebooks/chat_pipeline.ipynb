{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfae42b",
   "metadata": {},
   "source": [
    "### About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2604dba9",
   "metadata": {},
   "source": [
    "This notebook uses the following frameworks\n",
    "* Langchain\n",
    "\n",
    "* Langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc67d5",
   "metadata": {},
   "source": [
    "### 1. Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e14b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain_community langchain-qdrant langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba2f29b",
   "metadata": {},
   "source": [
    "### 2. Local models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94575916",
   "metadata": {},
   "source": [
    "Loading the embedding model \"sentence-camembert-large\" from hugging face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482de071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\foura\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name dangvantuan/sentence-camembert-large. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"dangvantuan/sentence-camembert-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272224fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HuggingFaceEmbeddings' object has no attribute 'get_sentence_embedding_dimension'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embeddings\u001b[38;5;241m.\u001b[39mget_sentence_embedding_dimension()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:892\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 892\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HuggingFaceEmbeddings' object has no attribute 'get_sentence_embedding_dimension'"
     ]
    }
   ],
   "source": [
    "embeddings.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dddf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "local_llm = \"mistral:7b-instruct\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "llm_json_mode = ChatOllama(model=local_llm, temperature=0, format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b28bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06eb40",
   "metadata": {},
   "source": [
    "### 3. Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42238797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a15f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import hashlib\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
    "\n",
    "# Helper function to convert string IDs to valid UUID-compatible IDs\n",
    "def string_to_uuid(string_id):\n",
    "    \"\"\"Convert a string to a deterministic UUID by hashing it\"\"\"\n",
    "    # Create MD5 hash of the string\n",
    "    hash_object = hashlib.md5(string_id.encode())\n",
    "    # Convert to hex\n",
    "    hex_dig = hash_object.hexdigest()\n",
    "    # Create a UUID from the hex string\n",
    "    return uuid.UUID(hex_dig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc03e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load your JSON file\n",
    "try:\n",
    "    with open('output_chunks.json', 'r', encoding='utf-8') as f:\n",
    "        documents = json.load(f)\n",
    "    print(f\"âœ“ Loaded {len(documents)} documents from output_chunks.json\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: output_chunks.json file not found!\")\n",
    "    sys.exit(1)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: Invalid JSON format in output_chunks.json!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 5. Create a collection\n",
    "collection_name = \"Auditron_legal_chunks\"\n",
    "print(f\"Creating collection '{collection_name}'...\")\n",
    "qdrant.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=model.get_sentence_embedding_dimension(), distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# 6. Process the documents\n",
    "print(\"Processing documents...\")\n",
    "total_chunks = sum(len(doc.get(\"chunks\", [])) for doc in documents)\n",
    "batch_size = 50\n",
    "processed_count = 0\n",
    "error_count = 0\n",
    "batch_points = []\n",
    "id_mapping = {}  # To store mapping between original IDs and UUID IDs\n",
    "\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    print(f\"Processing document {doc_idx+1}/{len(documents)}\")\n",
    "    chunks = doc.get(\"chunks\", [])\n",
    "    \n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        try:\n",
    "            # Extract text and ID\n",
    "            text = chunk.get(\"text\", \"\")\n",
    "            original_id = chunk.get(\"chunk_id\", f\"unknown_{doc_idx}_{chunk_idx}\")\n",
    "            \n",
    "            if not text.strip():  # Skip empty chunks\n",
    "                print(f\"Warning: Empty text in chunk {original_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Clean and truncate text if necessary to avoid index errors\n",
    "            # Some models have maximum input length limitations\n",
    "            max_text_length = 512  # Adjust based on your model's limitations\n",
    "            text = text.strip()[:max_text_length]\n",
    "            \n",
    "            # Convert string ID to UUID\n",
    "            point_id = string_to_uuid(original_id)\n",
    "            \n",
    "            # Save mapping\n",
    "            id_mapping[str(point_id)] = original_id\n",
    "            \n",
    "            # Generate embedding with error handling\n",
    "            try:\n",
    "                embedding = model.encode(text, show_progress_bar=False)\n",
    "            except Exception as embed_error:\n",
    "                print(f\"Embedding error for chunk {original_id}: {str(embed_error)}\")\n",
    "                # Try with a shorter text if it might be a length issue\n",
    "                if len(text) > 200:\n",
    "                    try:\n",
    "                        shorter_text = text[:200]\n",
    "                        print(f\"Retrying with shorter text for {original_id}\")\n",
    "                        embedding = model.encode(shorter_text, show_progress_bar=False)\n",
    "                    except Exception as retry_error:\n",
    "                        print(f\"Still failed with shorter text: {str(retry_error)}\")\n",
    "                        error_count += 1\n",
    "                        continue\n",
    "                else:\n",
    "                    error_count += 1\n",
    "                    continue\n",
    "            \n",
    "            # Create point with UUID\n",
    "            point = PointStruct(\n",
    "                id=str(point_id),\n",
    "                vector=embedding.tolist(),\n",
    "                payload={\n",
    "                    \"text\": text,\n",
    "                    \"original_id\": original_id,  # Keep original ID in payload\n",
    "                    \"structures\": chunk.get(\"structures\", []),\n",
    "                    \"document_path\": chunk.get(\"document_path\", []),\n",
    "                    \"metadata\": chunk.get(\"metadata\", {})\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Add to batch\n",
    "            batch_points.append(point)\n",
    "            processed_count += 1\n",
    "            \n",
    "            # If batch is full, upload to Qdrant\n",
    "            if len(batch_points) >= batch_size:\n",
    "                qdrant.upsert(\n",
    "                    collection_name=collection_name,\n",
    "                    points=batch_points,\n",
    "                )\n",
    "                print(f\"Uploaded batch: {processed_count}/{total_chunks} chunks ({error_count} errors so far)\")\n",
    "                batch_points = []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk {original_id}: {str(e)}\")\n",
    "            error_count += 1\n",
    "\n",
    "# Upload any remaining points\n",
    "if batch_points:\n",
    "    qdrant.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=batch_points,\n",
    "    )\n",
    "    print(f\"Uploaded final batch: {processed_count}/{total_chunks} chunks\")\n",
    "\n",
    "# Save ID mapping for reference (optional)\n",
    "try:\n",
    "    with open('id_mapping.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(id_mapping, f, indent=2)\n",
    "    print(\"âœ“ Saved ID mapping to id_mapping.json\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not save ID mapping: {str(e)}\")\n",
    "\n",
    "print(f\"âœ… Successfully processed {processed_count}/{total_chunks} chunks into Qdrant collection '{collection_name}'!\")\n",
    "print(f\"Total errors encountered: {error_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa01f5b",
   "metadata": {},
   "source": [
    "### 4. Retrieving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c868e460",
   "metadata": {},
   "source": [
    "**4.1 Semantic search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import SearchParams\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "# 3. Create the vector store with LangChain\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrant,\n",
    "    collection_name=\"Auditron_legal_chunks\",  # Your collection name\n",
    "    content_payload_key=\"text\", \n",
    "    embedding=embeddings,\n",
    ")\n",
    "#    search_params=SearchParams(hnsw_ef=128)  # Your search params\n",
    "# 4. Create the retriever from the vector store\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 5. Use the retriever\n",
    "query = \"Quel est le nouveau taux unifiÃ© de retenue Ã  la source applicable aux loyers, rÃ©munÃ©rations non commerciales, honoraires et commissions en Tunisie depuis l'adoption de la loi NÂ° 2020-46 du 23 dÃ©cembre 2020?\"\n",
    "documents = retriever.invoke(query)\n",
    "\n",
    "# The retrieved documents will include content and metadata\n",
    "for doc in documents:\n",
    "    print(doc.page_content)  # Access the content\n",
    "    print(doc.metadata)      # Access the metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7780c0",
   "metadata": {},
   "source": [
    "### Document re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d19070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "### Retrieval Grader\n",
    "\n",
    "# Doc grader instructions\n",
    "doc_grader_instructions = \"\"\"Vous Ãªtes un modÃ¨le chargÃ© dâ€™Ã©valuer la pertinence dâ€™un document rÃ©cupÃ©rÃ© par rapport Ã  une question utilisateur.\n",
    "\n",
    "Si le document contient des mots-clÃ©s ou un sens sÃ©mantique liÃ© Ã  la question, considÃ©rez-le comme pertinent.\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "doc_grader_prompt = \"\"\"Voici le document rÃ©cupÃ©rÃ© : \\n\\n {document} \\n\\n Voici la question de l'utilisateur : \\n\\n {question}.\n",
    "\n",
    "Ã‰valuez soigneusement et objectivement si le document contient au moins une information pertinente en lien avec la question.\n",
    "\n",
    "Retournez un JSON avec une clÃ© unique, binary_score, qui sera 'oui' ou 'non' pour indiquer si le document contient au moins une information pertinente pour la question.\"\"\"\n",
    "# Test\n",
    "question = \"Quel est le nouveau taux unifiÃ© de retenue Ã  la source applicable aux loyers, rÃ©munÃ©rations non commerciales, honoraires et commissions en Tunisie depuis l'adoption de la loi NÂ° 2020-46 du 23 dÃ©cembre 2020?\"\n",
    "\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[0].page_content\n",
    "\n",
    "doc_grader_prompt_formatted = doc_grader_prompt.format(\n",
    "    document=doc_txt, question=question\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=doc_grader_instructions)]\n",
    "    + [HumanMessage(content=doc_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e749dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[2].page_content\n",
    "\n",
    "doc_grader_prompt_formatted = doc_grader_prompt.format(\n",
    "    document=doc_txt, question=question\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=doc_grader_instructions)]\n",
    "    + [HumanMessage(content=doc_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbde3f0",
   "metadata": {},
   "source": [
    "**4.2 Implementig Hybrid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever  # Changed import location\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Load all points from Qdrant\n",
    "response = qdrant.scroll(\n",
    "    collection_name=\"Auditron_legal_chunks\",\n",
    "    limit=10_000,  # Increase if needed, Qdrant supports pagination\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "# Convert Qdrant points to LangChain Documents\n",
    "all_documents = []\n",
    "for point in response[0]:  # response = (points, next_page_offset)\n",
    "    payload = point.payload\n",
    "    content = payload.get(\"text\", \"\")\n",
    "    metadata = {k: v for k, v in payload.items() if k != \"text\"}\n",
    "    all_documents.append(Document(page_content=content, metadata=metadata))\n",
    "    # Initialize the BM25 retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(all_documents)\n",
    "bm25_retriever.k = 3  # Retrieve top 5 results\n",
    "\n",
    "# Create the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, retriever], \n",
    "    weights=[0.4, 0.6]  # You can adjust these weights based on performance\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e3a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query\n",
    "query = \"Quel est le taux de retenue Ã  la source sur les dividendes distribuÃ©s par des sociÃ©tÃ©s tunisiennes Ã  des personnes non rÃ©sidentes, et comment une convention de non-double imposition peut-elle modifier ce taux pour les bÃ©nÃ©ficiaires dâ€™une telle convention ?\"\n",
    "# Use the ensemble retriever\n",
    "documents = ensemble_retriever.invoke(query)\n",
    "\n",
    "# The retrieved documents will include content and metadata\n",
    "for doc in documents:\n",
    "    print(doc.page_content)  # Access the content\n",
    "    print(doc.metadata)      # Access the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = ensemble_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd7df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9396b",
   "metadata": {},
   "source": [
    "**4.3 Relevancy threshold** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe5c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import SearchParams\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create the vector store with LangChain\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=qdrant,\n",
    "    collection_name=\"Auditron_legal_chunks\",  # Your collection name\n",
    "    content_payload_key=\"text\", \n",
    "    embedding=embeddings,\n",
    ")\n",
    "#    search_params=SearchParams(hnsw_ef=128)  # Your search params\n",
    "\n",
    "# 4. Create the retriever from the vector store\n",
    "qdrant_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"score_threshold\": 0.4\n",
    "    }\n",
    ")\n",
    "\n",
    "# Load all points from Qdrant\n",
    "response = qdrant.scroll(\n",
    "    collection_name=\"Auditron_legal_chunks\",\n",
    "    limit=10_000,  # Increase if needed, Qdrant supports pagination\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "all_documents = []\n",
    "for point in response[0]:  # response = (points, next_page_offset)\n",
    "    payload = point.payload\n",
    "    content = payload.get(\"text\", \"\")\n",
    "    metadata = {k: v for k, v in payload.items() if k != \"text\"}\n",
    "    all_documents.append(Document(page_content=content, metadata=metadata))\n",
    "    \n",
    "# Set up your retrievers with the with_score parameter\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    all_documents,\n",
    "    k=5,\n",
    "    with_score=True  # This returns scores with documents\n",
    ")\n",
    "\n",
    "# Combine them\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, qdrant_retriever], \n",
    "    weights=[0.4, 0.6]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_threshold(query):\n",
    "    docs = ensemble_retriever.invoke(query)\n",
    "    for doc in docs:\n",
    "        print(f\"Score: {doc.metadata.get('score', 'N/A')}, Content: {doc.page_content}\")\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "results = retrieve_with_threshold(\"Quel est le taux de la retenue Ã  la source sur les dividendes versÃ©s Ã  une personne morale rÃ©sidente ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9758ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a841cf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name dangvantuan/sentence-camembert-large. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 [Score: 0.658]\n",
      "RETENUES A LA SOURCE ARTICLE 52 :\n",
      "\n",
      "L'impÃ´t sur le revenu et l'impÃ´t sur les sociÃ©tÃ©s font l'objet d'une retenue Ã  la source aux taux suivants :...\n",
      "\n",
      "Document 2 [Score: 0.662]\n",
      "b- Les retenues Ã  la source Lâ€™impÃ´t sur le revenu et lâ€™impÃ´t sur les sociÃ©tÃ©s font lâ€™objet dâ€™une retenue Ã  la source, et ce, pour les montants qui sont dans le champ dâ€™application de ladite retenue et payÃ©s par les personnes soumises Ã  lâ€™obligation dâ€™effectuer la retenue Ã  la source....\n",
      "\n",
      "Document 3 [Score: 0.660]\n",
      "Pour la dÃ©termination du prix (1) Ce taux sâ€™applique aux revenus distribuÃ©s Ã  partir du 01/01/2018 et demeurent exonÃ©rÃ©s de lâ€™impÃ´t sur les bÃ©nÃ©fices distribuÃ©s les opÃ©rations de distribution de bÃ©nÃ©fices Ã  partir des fonds propres figurant au bilan de la sociÃ©tÃ© distributrice au 31 dÃ©cembre 2013, Ã ...\n",
      "\n",
      "Document 4 [Score: 0.651]\n",
      "Lâ€™impÃ´t sur le revenu dÃ» au titre de la plus-value Sous rÃ©serve des exonÃ©rations prÃ©vues par la lÃ©gislation en vigueur, la plus- value rÃ©alisÃ©e par les personnes physiques et provenant de la cession des titres non rattachÃ©s Ã  un bilan et des droits y relatifs, est soumise Ã  lâ€™impÃ´t sur le revenu sel...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foura\\AppData\\Local\\Temp\\ipykernel_23092\\1034766933.py:23: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = self.vectorstore.client.search(\n"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from typing import List, Any\n",
    "from pydantic import Field\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# 1. Updated Qdrant retriever with explicit embeddings\n",
    "class QdrantScoreRetriever(BaseRetriever):\n",
    "    vectorstore: QdrantVectorStore = Field(...)\n",
    "    embeddings: Embeddings = Field(...)  # Explicit embeddings field\n",
    "    k: int = Field(default=5)\n",
    "    score_threshold: float = Field(default=0.4)\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        # Get embedding using the explicit embeddings model\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        \n",
    "        # Search Qdrant with score threshold\n",
    "        results = self.vectorstore.client.search(\n",
    "            collection_name=self.vectorstore.collection_name,\n",
    "            query_vector=query_embedding,\n",
    "            limit=self.k,\n",
    "            score_threshold=self.score_threshold,\n",
    "            with_payload=True\n",
    "        )\n",
    "\n",
    "        documents = []\n",
    "        for result in results:\n",
    "            content = result.payload.get(\"text\", \"\")\n",
    "            metadata = {k: v for k, v in result.payload.items() if k != \"text\"}\n",
    "            metadata[\"score\"] = result.score  # Store similarity score\n",
    "            documents.append(Document(\n",
    "                page_content=content,\n",
    "                metadata=metadata\n",
    "            ))\n",
    "        \n",
    "        return documents\n",
    "\n",
    "# 2. Initialize components\n",
    "qdrant = qdrant = QdrantClient(url=\"http://localhost:6333\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"dangvantuan/sentence-camembert-large\")\n",
    "\n",
    "# Create vector store\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=qdrant,\n",
    "    collection_name=\"Auditron_legal_chunks\",\n",
    "    content_payload_key=\"text\",\n",
    "    embedding=embeddings,  # This might not be needed depending on your Qdrant setup\n",
    ")\n",
    "\n",
    "# 3. Create Qdrant retriever with explicit embeddings\n",
    "qdrant_retriever = QdrantScoreRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    embeddings=embeddings,  # Pass embeddings explicitly\n",
    "    k=5,\n",
    "    score_threshold=0.4\n",
    ")\n",
    "\n",
    "# Load BM25 documents\n",
    "response = qdrant.scroll(\n",
    "    collection_name=\"Auditron_legal_chunks\",\n",
    "    limit=10_000,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "all_documents = [\n",
    "    Document(\n",
    "        page_content=point.payload.get(\"text\", \"\"),\n",
    "        metadata={k: v for k, v in point.payload.items() if k != \"text\"}\n",
    "    )\n",
    "    for point in response[0]\n",
    "]\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    all_documents,\n",
    "    k=5,\n",
    "    with_score=True\n",
    ")\n",
    "\n",
    "# 4. Create ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, qdrant_retriever],\n",
    "    weights=[0.4, 0.6]\n",
    ")\n",
    "\n",
    "# 5. Search function with threshold\n",
    "def retrieve_with_threshold(query: str, threshold: float = 0.4) -> List[Document]:\n",
    "    \"\"\"Retrieve documents with combined score above threshold\"\"\"\n",
    "    docs = ensemble_retriever.invoke(query)\n",
    "    \n",
    "    # Filter documents by combined score\n",
    "    filtered_docs = [\n",
    "        doc for doc in docs\n",
    "        if doc.metadata.get(\"score\", 0) >= threshold\n",
    "    ]\n",
    "    \n",
    "    # Print results\n",
    "    for i, doc in enumerate(filtered_docs, 1):\n",
    "        print(f\"Document {i} [Score: {doc.metadata['score']:.3f}]\")\n",
    "        print(doc.page_content[:300] + \"...\\n\")\n",
    "    \n",
    "    return filtered_docs\n",
    "\n",
    "# 6. Execute the search\n",
    "results = retrieve_with_threshold(\n",
    "    \"Quel est le taux de la retenue Ã  la source sur les dividendes versÃ©s Ã  une personne morale rÃ©sidente ?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3e18a2",
   "metadata": {},
   "source": [
    "### 5. Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc2362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate\n",
    "\n",
    "# Prompt\n",
    "rag_prompt = \"\"\"Vous Ãªtes un assistant pour des tÃ¢ches de question-rÃ©ponse.\n",
    "\n",
    "Voici le contexte Ã  utiliser pour rÃ©pondre Ã  la question :\n",
    "\n",
    "{context}\n",
    "\n",
    "RÃ©flÃ©chissez soigneusement au contexte ci-dessus.\n",
    "\n",
    "Maintenant, examinez la question de l'utilisateur :\n",
    "\n",
    "{question}\n",
    "\n",
    "Fournissez une rÃ©ponse Ã  cette question en utilisant uniquement le contexte ci-dessus.\n",
    "\n",
    "Utilisez un maximum de trois phrases et gardez la rÃ©ponse concise.\n",
    "\n",
    "RÃ©ponse :\"\"\"\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Test\n",
    "query = '''TEJ'''\n",
    "docs = ensemble_retriever.invoke(query)\n",
    "docs_txt = format_docs(docs)\n",
    "rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=query)\n",
    "generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "print(generation.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d682cc",
   "metadata": {},
   "source": [
    "Hallucination grader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8372b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "# Hallucination grader instructions\n",
    "hallucination_grader_instructions = \"\"\"\n",
    "\n",
    "Vous Ãªtes un enseignant en train de corriger un quiz.\n",
    "\n",
    "Vous recevrez des FAITS et une RÃ‰PONSE D'Ã‰LÃˆVE.\n",
    "\n",
    "Voici les critÃ¨res de notation Ã  suivre :\n",
    "\n",
    "(1) Assurez-vous que la RÃ‰PONSE DE L'Ã‰LÃˆVE est bien fondÃ©e sur les FAITS.\n",
    "\n",
    "(2) Assurez-vous que la RÃ‰PONSE DE L'Ã‰LÃˆVE ne contient pas d'informations Â« hallucinÃ©es Â» qui sortent du cadre des FAITS.\n",
    "\n",
    "Note :\n",
    "\n",
    "Une note de oui signifie que la rÃ©ponse de l'Ã©lÃ¨ve respecte tous les critÃ¨res. Câ€™est la note la plus Ã©levÃ©e (meilleure).\n",
    "\n",
    "Une note de non signifie que la rÃ©ponse de l'Ã©lÃ¨ve ne respecte pas tous les critÃ¨res. Câ€™est la note la plus basse que vous pouvez attribuer.\n",
    "\n",
    "Expliquez votre raisonnement Ã©tape par Ã©tape afin de garantir la justesse de votre raisonnement et de votre conclusion.\n",
    "\n",
    "Ã‰vitez dâ€™Ã©noncer directement la bonne rÃ©ponse dÃ¨s le dÃ©part.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Grader prompt\n",
    "hallucination_grader_prompt = \"\"\"FAITS : \\n\\n {documents} \\n\\n RÃ‰PONSE DE L'Ã‰LÃˆVE : {generation}.\n",
    "\n",
    "Retournez un JSON avec deux clÃ©s :  \n",
    "- binary_score : une valeur 'oui' ou 'non' indiquant si la RÃ‰PONSE DE L'Ã‰LÃˆVE est bien fondÃ©e sur les FAITS.  \n",
    "- explanation : une explication justifiant la note attribuÃ©e.\n",
    "\"\"\"\n",
    "\n",
    "# Test using documents and generation from above\n",
    "hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(\n",
    "    documents=docs_txt, generation=generation.content\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=hallucination_grader_instructions)]\n",
    "    + [HumanMessage(content=hallucination_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46427e26",
   "metadata": {},
   "source": [
    "Answer grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Answer Grader\n",
    "\n",
    "# Answer grader instructions\n",
    "answer_grader_instructions = \"\"\"Vous Ãªtes un enseignant en train de corriger un quiz.\n",
    "\n",
    "Vous recevrez une QUESTION et une RÃ‰PONSE D'Ã‰LÃˆVE.\n",
    "\n",
    "Voici les critÃ¨res de notation Ã  suivre :\n",
    "\n",
    "(1) La RÃ‰PONSE DE L'Ã‰LÃˆVE aide Ã  rÃ©pondre Ã  la QUESTION.\n",
    "\n",
    "Note :\n",
    "\n",
    "Une note de oui signifie que la rÃ©ponse de l'Ã©lÃ¨ve respecte tous les critÃ¨res. Câ€™est la note la plus Ã©levÃ©e (meilleure).\n",
    "\n",
    "Lâ€™Ã©lÃ¨ve peut recevoir une note de oui mÃªme si la rÃ©ponse contient des informations supplÃ©mentaires qui ne sont pas explicitement demandÃ©es dans la question.\n",
    "\n",
    "Une note de non signifie que la rÃ©ponse de l'Ã©lÃ¨ve ne respecte pas tous les critÃ¨res. Câ€™est la note la plus basse que vous pouvez attribuer.\n",
    "\n",
    "Expliquez votre raisonnement Ã©tape par Ã©tape afin de garantir la justesse de votre raisonnement et de votre conclusion.\n",
    "\n",
    "Ã‰vitez dâ€™Ã©noncer directement la bonne rÃ©ponse dÃ¨s le dÃ©part.\n",
    "\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "answer_grader_prompt = \"\"\"QUESTION : \\n\\n {question} \\n\\n RÃ‰PONSE DE L'Ã‰LÃˆVE : {generation}.\n",
    "\n",
    "Retournez un JSON avec deux clÃ©s :  \n",
    "- binary_score : une valeur 'oui' ou 'non' indiquant si la RÃ‰PONSE DE L'Ã‰LÃˆVE respecte les critÃ¨res.  \n",
    "- explanation : une explication justifiant la note attribuÃ©e.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Test\n",
    "answer = generation.content\n",
    "\n",
    "# Test using question and generation from above\n",
    "answer_grader_prompt_formatted = answer_grader_prompt.format(\n",
    "    question=question, generation=answer\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=answer_grader_instructions)]\n",
    "    + [HumanMessage(content=answer_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d410f",
   "metadata": {},
   "source": [
    "### 6. ChatAgent with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01b167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auditron_venv",
   "language": "python",
   "name": "auditron_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
