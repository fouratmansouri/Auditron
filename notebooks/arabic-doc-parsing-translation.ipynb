{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11380255,"sourceType":"datasetVersion","datasetId":7125438}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pymupdf transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T21:01:33.306456Z","iopub.execute_input":"2025-04-12T21:01:33.306675Z","iopub.status.idle":"2025-04-12T21:02:47.699463Z","shell.execute_reply.started":"2025-04-12T21:01:33.306657Z","shell.execute_reply":"2025-04-12T21:02:47.698291Z"}},"outputs":[{"name":"stdout","text":"Collecting pymupdf\n  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymupdf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pymupdf-1.25.5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport re\nfrom pathlib import Path\nimport fitz  # PyMuPDF\nimport torch\nfrom transformers import MarianMTModel, MarianTokenizer\n\ndef extract_text_from_pdf(pdf_path):\n    \"\"\"Extract text from PDF while preserving structure.\"\"\"\n    doc = fitz.open(pdf_path)\n    full_text = []\n    \n    for page_num in range(len(doc)):\n        page = doc.load_page(page_num)\n        text = page.get_text()\n        full_text.append(text)\n    \n    # Join all pages text\n    complete_text = \"\\n\".join(full_text)\n    \n    # Clean up extra whitespace while preserving paragraph structure\n    complete_text = re.sub(r'\\n\\s*\\n', '\\n\\n', complete_text)\n    complete_text = re.sub(r' +', ' ', complete_text)\n    \n    return complete_text\n\ndef detect_language(text):\n    \"\"\"Simple language detection based on script.\"\"\"\n    # Check for Arabic characters\n    if re.search(r'[\\u0600-\\u06FF]', text):\n        return 'ar'\n    # Check for Latin characters (covers French, English, etc.)\n    elif re.search(r'[a-zA-Z]', text):\n        return 'en'\n    else:\n        return 'unknown'\n\ndef translate_text(text, source_lang, target_lang='fr'):\n    \"\"\"Translate text using Opus-MT model.\"\"\"\n    model_name = f\"Helsinki-NLP/opus-mt-{source_lang}-{target_lang}\"\n    \n    try:\n        print(f\"Loading translation model: {model_name}\")\n        tokenizer = MarianTokenizer.from_pretrained(model_name)\n        model = MarianMTModel.from_pretrained(model_name)\n        \n        # Process text in chunks to avoid exceeding max token length\n        max_length = tokenizer.model_max_length\n        chunks = []\n        \n        # Split by paragraphs\n        paragraphs = text.split('\\n\\n')\n        current_chunk = \"\"\n        \n        for paragraph in paragraphs:\n            # If adding this paragraph would exceed max length, save current chunk and start new one\n            if len(tokenizer.encode(current_chunk + paragraph)) > max_length - 10:  # Leave some margin\n                chunks.append(current_chunk.strip())\n                current_chunk = paragraph + \"\\n\\n\"\n            else:\n                current_chunk += paragraph + \"\\n\\n\"\n        \n        # Add the last chunk if not empty\n        if current_chunk.strip():\n            chunks.append(current_chunk.strip())\n        \n        # Translate each chunk\n        translated_chunks = []\n        for i, chunk in enumerate(chunks):\n            print(f\"Translating chunk {i+1}/{len(chunks)}...\")\n            encoded = tokenizer(chunk, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n            translated = model.generate(**encoded)\n            translated_text = tokenizer.batch_decode(translated, skip_special_tokens=True)[0]\n            translated_chunks.append(translated_text)\n        \n        # Join all translated chunks\n        translated_text = \"\\n\\n\".join(translated_chunks)\n        return translated_text\n        \n    except Exception as e:\n        print(f\"Translation error: {e}\")\n        # Try fallback options\n        if source_lang == 'ar':\n            try:\n                print(\"Attempting to use multilingual model...\")\n                return translate_text(text, \"apc\", target_lang)  # Try Arabic dialect\n            except:\n                print(\"All translation attempts failed. Returning original text.\")\n                return text\n        else:\n            return text\n\ndef process_document(input_file, output_file=None):\n    \"\"\"Process PDF document: extract text, detect language, translate, and save.\"\"\"\n    print(f\"Processing {input_file}...\")\n    \n    # Extract text from PDF\n    extracted_text = extract_text_from_pdf(input_file)\n    \n    # Save the extracted text for inspection\n    extracted_path = \"/kaggle/working/extracted_text.txt\"\n    with open(extracted_path, 'w', encoding='utf-8') as f:\n        f.write(extracted_text)\n    print(f\"Extracted text saved to {extracted_path}\")\n    \n    # Detect language\n    source_lang = detect_language(extracted_text)\n    print(f\"Detected language: {source_lang}\")\n    \n    if source_lang == 'unknown':\n        print(\"Could not detect language. Using 'ar' as default.\")\n        source_lang = 'ar'\n    \n    # Translate to French\n    if source_lang != 'fr':  # Skip translation if already French\n        print(f\"Translating from {source_lang} to French...\")\n        translated_text = translate_text(extracted_text, source_lang)\n    else:\n        translated_text = extracted_text\n        print(\"Document already in French. No translation needed.\")\n    \n    # Generate output filename if not provided\n    if not output_file:\n        input_path = Path(input_file)\n        output_file = input_path.with_stem(f\"{input_path.stem}_fr\").with_suffix('.txt')\n    \n    # Save translated text\n    with open(output_file, 'w', encoding='utf-8') as f:\n        f.write(translated_text)\n    \n    print(f\"Translation saved to {output_file}\")\n    return output_file\n\n# Check if a GPU is available and set device accordingly\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Hardcoded paths for Kaggle environment\ninput_pdf = \"/kaggle/input/note-commune/---06-1.pdf\"\noutput_file = \"/kaggle/working/translated_document_fr.txt\"\n\n# Check if the file exists\nif not os.path.exists(input_pdf):\n    print(f\"File not found: {input_pdf}\")\n    print(\"Available files in input directory:\")\n    input_dir = \"/kaggle/input\"\n    for root, dirs, files in os.walk(input_dir):\n        for file in files:\n            if file.endswith('.pdf'):\n                print(os.path.join(root, file))\n    \n    # Allow user to specify a different path\n    input_pdf = input(\"Enter the correct path to the PDF file: \")\n\n# Process the document\nif os.path.exists(input_pdf):\n    process_document(input_pdf, output_file)\n    \n    # Display the first few lines of the translated document\n    print(\"\\nPreview of translated document:\")\n    with open(output_file, \"r\", encoding=\"utf-8\") as f:\n        preview = f.read(1000)\n    print(preview + \"...\")\nelse:\n    print(f\"File not found: {input_pdf}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T21:05:57.515109Z","iopub.execute_input":"2025-04-12T21:05:57.515870Z","iopub.status.idle":"2025-04-12T21:06:17.105909Z","shell.execute_reply.started":"2025-04-12T21:05:57.515842Z","shell.execute_reply":"2025-04-12T21:06:17.105125Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nProcessing /kaggle/input/note-commune/---06-1.pdf...\nExtracted text saved to /kaggle/working/extracted_text.txt\nDetected language: ar\nTranslating from ar to French...\nLoading translation model: Helsinki-NLP/opus-mt-ar-fr\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72c2a4a4bc4b4e578f3b93e47cc5666a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/918k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10f7b037220c4a44add1d24a28f0f00e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/824k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5c1e331504e4b69a74f1e82b4463b30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e15bb1d1ffb6491aaba703bef2e73dbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a39c49d19c2d4af0b9759671ad6699b2"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/311M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b41c162c07144d6a1afe1758a2824ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d41dd2dc6b5a48799876d9a60c9b2399"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Translating chunk 1/2...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/311M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a1a475e61b342e0a247656a6add524f"}},"metadata":{}},{"name":"stdout","text":"Translating chunk 2/2...\nTranslation saved to /kaggle/working/translated_document_fr.txt\n\nPreview of translated document:\nSur ce sujet, il convient de préciser: 1. En ce qui concerne la vente de parcelles de terrain par les bailleurs de biens immobiliers, il s'agit de la vente de parcelles de terrain par les propriétaires de biens immobiliers: les salariés de la section 1 du chapitre 5 du chapitre 1 du Code de la valeur ajoutée sont soumis à la valeur ajoutée par les bailleurs de fonds immobiliers et, conformément aux dispositions du chapitre 58 du Code de la valeur ajoutée, la vente de parcelles de terrain par les bailleurs de fonds de la section 7 s'entend de la répartition des parcelles de terrain par la rubrique 1. En ce qui concerne la vente de parcelles de terrain par les bailleurs de fonds de la section 5 du chapitre 1 du Code de la valeur ajoutée, les travailleurs de la section 1 du chapitre 1 du Code de la valeur ajoutée sont soumis à la perte de la valeur ajoutée de la vente de biens immobiliers par les bailleurs de fonds immobiliers et selon les dispositions du chapitre 58 du Code de la valeur ...\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}