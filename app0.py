#!/usr/bin/env python
"""
Main application for tax rate verification processing.
"""
import json, re, math, pathlib, argparse, os
import pandas as pd
from flask import Flask, render_template, request
from tqdm import tqdm
from datetime import datetime

# Import from modular components
from models.utils import XLS_IN, JSON_RULES, rs_or_pct, guess_cat
from models.db import init_db, export_to_excel, get_connection, execute_query
from models.embeddings import get_faiss_retriever, build_faiss
from models.tax_classification import classify_transaction_with_llm, load_tax_rules
from models.sql_query import extract_sql_query, direct_sql_query, setup_deepseek_agent

# â”€â”€â”€ pipeline principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_pipeline(rebuild: bool=False):
    # 1. FAISS
    if rebuild:
        retriever = build_faiss()
        if retriever is None:
            print("âŒ Impossible de construire l'index FAISS. VÃ©rifiez le fichier JSON.")
            return
    
    retriever = get_faiss_retriever()
    if retriever is None:
        print("âŒ Impossible de charger l'index FAISS.")
        return

    # 2. Lire Excel (concat.toutes feuilles)
    try:
        xl = pd.ExcelFile(XLS_IN)
        df = pd.concat([xl.parse(s) for s in xl.sheet_names], ignore_index=True)
        print(f"âœ… Fichier Excel chargÃ©: {len(df)} lignes")
    except Exception as e:
        print(f"âŒ Erreur lors du chargement du fichier Excel: {e}")
        return

    # 3. DÃ©tecter la colonne taux d'abord sur le nom
    taux_cols = [c for c in df.columns if "taux" in c.lower()]
    if taux_cols:
        TAUX_COL = taux_cols[0]
    else:
        TAUX_COL = next((c for c in df.columns
                       if df[c].astype(str).str.contains(r"%|rs", case=False, na=False).any()), None)
    
    if not TAUX_COL:
        print("âŒ Impossible de trouver une colonne de taux dans le fichier Excel")
        return
    
    print(f"âœ… Colonne de taux identifiÃ©e: {TAUX_COL}")

    # 4. Charger les rÃ¨gles fiscales depuis le JSON
    try:
        with open(JSON_RULES, encoding="utf-8") as f:
            rules_json = json.load(f)
        print(f"âœ… {len(rules_json)} rÃ¨gles JSON chargÃ©es pour la classification")
    except Exception as e:
        print(f"âŒ Erreur lors du chargement des rÃ¨gles JSON: {e}")
        rules_json = []  # Tableau vide en cas d'Ã©chec
    
    # Charger les rÃ¨gles fiscales
    tax_rules = load_tax_rules()

    # 5. Remplir la BDD
    conn = init_db()
    cur = conn.cursor()

    # Statistiques de classification
    stats = {"llm": 0, "total": 0, "fails": 0}

    for idx, row in tqdm(df.iterrows(), total=len(df), desc="Traitement des transactions"):
        try:
            date_iso = pd.to_datetime(row["Date"]).date().isoformat()
            svc = str(row.get("intitulCompta", row.get("Service", "")))
            montant = float(str(row.get("MontantTTC", row.get("Montant", 0)))
                            .replace(" ","").replace(" ","").replace(",",".")) 
            raw_taux = str(row.get(TAUX_COL,"")).strip()
            tap = rs_or_pct(raw_taux)
            cat = guess_cat(svc)  # Gardons cette estimation initiale comme backup
            year = pd.to_datetime(row["Date"]).year

            stats["total"] += 1

            # Classification automatique avec LLM
            print(f"ðŸ” Classification de: '{svc}' (montant: {montant})")
            llm_result = classify_transaction_with_llm(svc, montant, year, rules_json)
            if llm_result:
                # Utiliser la classification du LLM
                stats["llm"] += 1
                taux_att = llm_result.get("taux", math.nan)
                ref = llm_result.get("ref", "Non spÃ©cifiÃ©")
                doc = llm_result.get("doc", "Non spÃ©cifiÃ©")
                date_app = llm_result.get("date_app", "Non spÃ©cifiÃ©")
                parag = llm_result.get("parag", "Non spÃ©cifiÃ©")
                lien = llm_result.get("lien", "")
                benef = llm_result.get("benef", "Non spÃ©cifiÃ©")
                seuil = "Non spÃ©cifiÃ©"
                
                print(f"âœ“ Classification LLM: {llm_result.get('categorie')}, taux={taux_att}%")
            else:
                # Ã‰chec de classification - uniquement des valeurs par dÃ©faut
                stats["fails"] = stats.get("fails", 0) + 1
                print(f"âŒ Classification LLM Ã©chouÃ©e pour '{svc}'")
                taux_att = math.nan
                ref = "Classification Ã©chouÃ©e"
                doc = "Non disponible"
                date_app = "Non disponible"
                parag = "Classification automatique impossible"
                lien = ""
                benef = "Non spÃ©cifiÃ©"
                seuil = "Non spÃ©cifiÃ©"

            # VÃ©rification stricte du taux (sans marge d'erreur)
            correct = (not math.isnan(tap) and not math.isnan(taux_att) and tap == taux_att)
            statut = "Correcte" if correct else "Incorrecte"

            # Insertion dans la base de donnÃ©es
            cur.execute("""
            INSERT INTO transactions
              (idx, date, service, montant, raw_taux, taux_applique,
               statut, taux_attendu, source_ref, document_source,
               date_application, paragraphe, lien_source, beneficiaire, seuil)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
              idx, date_iso, svc, montant, raw_taux, tap,
              statut, taux_att, ref, doc,
              date_app, parag, lien, benef, seuil
            ))
        except Exception as e:
            print(f"âŒ Erreur lors du traitement de la ligne {idx}: {e}")

    # Statistiques de classification
    print(f"\nStatistiques de classification:")
    if stats["total"] > 0:
        print(f"  Total: {stats['total']} transactions")
        print(f"  LLM: {stats['llm']} transactions ({stats['llm']/stats['total']*100:.1f}%)")
        print(f"  Ã‰checs: {stats.get('fails', 0)} transactions ({stats.get('fails', 0)/stats['total']*100:.1f}%)")
    else:
        print("  Aucune transaction traitÃ©e")
        
    # Mise Ã  jour du fichier Excel avec les donnÃ©es enrichies
    conn.commit()
    export_to_excel(conn)
    conn.close()
    print("âœ… Base SQLite et fichier Excel mis Ã  jour avec donnÃ©es enrichies")

# â”€â”€â”€ Flask â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = Flask(__name__)

@app.route("/", methods=["GET", "POST"])
def table():
    conn = get_connection()
    
    result = None
    query = ""
    sql_query = ""
    error = None
    rows = None
    filtered = False
    aggregate_result = None  # Pour stocker les rÃ©sultats d'agrÃ©gation
    show_detailed = True     # Toujours afficher les dÃ©tails enrichis
    
    if request.method == "POST":
        query = request.form.get("query", "")
        if query:
            sql_found = False
            
            # Tenter de gÃ©nÃ©rer une requÃªte SQL
            try:
                print(f"Tentative de gÃ©nÃ©ration directe SQL pour: {query}")
                direct_sql, direct_error = direct_sql_query(query)
                
                if direct_sql:
                    sql_query = direct_sql
                    sql_found = True
                    print(f"RequÃªte SQL gÃ©nÃ©rÃ©e directement: {sql_query}")
                else:
                    print(f"La gÃ©nÃ©ration directe a Ã©chouÃ©: {direct_error}")
                    
                    # Si la gÃ©nÃ©ration directe Ã©choue, essayer avec l'agent DeepSeek
                    print(f"Tentative avec l'agent DeepSeek pour: {query}")
                    try:
                        agent = setup_deepseek_agent()
                        result_obj = agent.invoke({"input": query})
                        
                        # Imprimer la rÃ©ponse brute pour le dÃ©bogage
                        print(f"RÃ©ponse brute de l'agent: {result_obj}")
                        
                        # Extraire la requÃªte SQL des logs ou du rÃ©sultat
                        if hasattr(agent, "agent_executor") and hasattr(agent.agent_executor, "logs"):
                            logs = agent.agent_executor.logs
                            print(f"Logs de l'agent disponibles: {logs}")
                            extracted_sql = extract_sql_query(logs)
                            if extracted_sql:
                                sql_query = extracted_sql
                                sql_found = True
                        
                        # Sinon chercher dans le rÃ©sultat brut
                        if not sql_found and result_obj:
                            result_text = str(result_obj)
                            print(f"Analyse du rÃ©sultat brut: {result_text}")
                            extracted_sql = extract_sql_query(result_text)
                            if extracted_sql:
                                sql_query = extracted_sql
                                sql_found = True
                    except Exception as agent_error:
                        print(f"Erreur avec l'agent DeepSeek: {agent_error}")
            
            except Exception as e:
                error = f"Erreur d'exÃ©cution: {str(e)}"
                print(f"Erreur: {error}")
            
            # Si SQL trouvÃ©, l'exÃ©cuter
            if sql_found and sql_query:
                # Nettoyer la requÃªte - extraire uniquement jusqu'au premier point-virgule
                if ";" in sql_query:
                    sql_query = sql_query.split(";")[0].strip() + ";"
                
                # Convertir 'FETCH FIRST n ROWS' en 'LIMIT n' pour SQLite
                sql_query = re.sub(r"FETCH\s+FIRST\s+(\d+)\s+ROWS", r"LIMIT \1", sql_query, flags=re.IGNORECASE)
                
                print(f"ExÃ©cution de la requÃªte SQL: {sql_query}")
                
                try:
                    # VÃ©rifier si c'est une requÃªte d'agrÃ©gation
                    is_aggregation = bool(re.search(r"(SUM|AVG|COUNT|MIN|MAX|TOTAL)\s*\(", sql_query, re.IGNORECASE))
                    
                    # ExÃ©cuter la requÃªte
                    rows = execute_query(sql_query)
                    filtered = True
                    
                    # Traitement spÃ©cial pour les requÃªtes d'agrÃ©gation
                    if is_aggregation and len(rows) == 1:
                        # RÃ©cupÃ©rer le nom de la colonne et la valeur
                        first_row = rows[0]
                        column_names = first_row.keys()
                        column_name = column_names[0] if len(column_names) > 0 else "RÃ©sultat"
                        value = first_row[0] if len(first_row) > 0 else None
                        
                        # Personnaliser l'affichage selon le type d'agrÃ©gation
                        if ("SUM" in sql_query.upper() or "TOTAL" in sql_query.upper()) and "montant" in sql_query.lower():
                            aggregate_result = {
                                "type": "sum",
                                "label": "Somme totale des montants",
                                "value": value,
                                "formatted": f"{value:.2f}" if value is not None else "0.00"
                            }
                        elif "COUNT" in sql_query.upper():
                            aggregate_result = {
                                "type": "count",
                                "label": "Nombre de transactions",
                                "value": value,
                                "formatted": str(value) if value is not None else "0"
                            }
                        else:
                            # Format gÃ©nÃ©rique pour d'autres types d'agrÃ©gation
                            aggregate_result = {
                                "type": "generic",
                                "label": column_name.replace("_", " ").title(),
                                "value": value,
                                "formatted": str(value) if value is not None else "-"
                            }
                    
                    result = f"RequÃªte SQL exÃ©cutÃ©e avec succÃ¨s."
                except Exception as e:
                    error = f"Erreur SQL: {str(e)}"
                    rows = None
            else:
                error = "Aucune requÃªte SQL valide n'a pu Ãªtre gÃ©nÃ©rÃ©e."
    
    # Afficher toutes les transactions si aucune requÃªte n'a Ã©tÃ© exÃ©cutÃ©e
    if rows is None:
        rows = execute_query("SELECT * FROM transactions")
        filtered = False
    
    return render_template(
        "table.html", 
        rows=rows, 
        year=datetime.now().year,
        result=result,
        query=query,
        sql_query=sql_query,
        error=error,
        filtered=filtered,
        aggregate_result=aggregate_result,
        show_detailed=show_detailed
    )

# â”€â”€â”€ CLI + lancement Flask â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    p = argparse.ArgumentParser()
    p.add_argument("--rebuild", action="store_true",
                   help="reconstruit l'index FAISS et la BDD")
    args = p.parse_args()
    run_pipeline(rebuild=args.rebuild)
    if not args.rebuild:
        app.run(debug=True, port=8000)