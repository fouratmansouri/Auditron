#!/usr/bin/env python
import sqlite3
import pandas as pd
from config import DB_PATH

def init_db():
    """Initialise la base de donn√©es SQLite"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("DROP TABLE IF EXISTS transactions")
    c.execute("""
    CREATE TABLE transactions(
      idx INTEGER PRIMARY KEY,
      date TEXT,
      service TEXT,
      montant REAL,
      raw_taux TEXT,
      taux_applique REAL,
      statut TEXT,
      taux_attendu REAL,
      source_ref TEXT,
      document_source TEXT,
      date_application TEXT,
      paragraphe TEXT,
      lien_source TEXT,
      beneficiaire TEXT,
      seuil TEXT
    )""")
    conn.commit()
    return conn

def get_connection():
    """Retourne une connexion √† la base de donn√©es avec row_factory configur√©"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn

def execute_query(query, params=None):
    """Ex√©cute une requ√™te SQL et retourne les r√©sultats"""
    conn = get_connection()
    try:
        if params:
            rows = conn.execute(query, params).fetchall()
        else:
            rows = conn.execute(query).fetchall()
        return rows
    except sqlite3.Error as e:
        print(f"Erreur SQL: {str(e)}")
        return None
    finally:
        conn.close()

def insert_transaction(idx, date_iso, service, montant, raw_taux, tap, 
                       statut, taux_att, ref, doc, date_app, parag, lien, benef, seuil):
    """Ins√®re une transaction dans la base de donn√©es"""
    conn = get_connection()
    try:
        conn.execute("""
        INSERT INTO transactions
          (idx, date, service, montant, raw_taux, taux_applique,
           statut, taux_attendu, source_ref, document_source,
           date_application, paragraphe, lien_source, beneficiaire, seuil)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
          idx, date_iso, service, montant, raw_taux, tap,
          statut, taux_att, ref, doc,
          date_app, parag, lien, benef, seuil
        ))
        conn.commit()
        return True
    except sqlite3.Error as e:
        print(f"Erreur d'insertion: {str(e)}")
        return False
    finally:
        conn.close()

def get_all_transactions():
    """Retourne toutes les transactions"""
    return execute_query("SELECT * FROM transactions")

"""
Vector embeddings and FAISS operations.
"""
import os, re, json
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from models.utils import JSON_RULES, FAISS_DIR, EMBED_MODEL

# Initialize embeddings model with a try-except block to handle memory issues
try:
    # Try using a smaller model first
    embedder = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    print("‚úÖ Using all-MiniLM-L6-v2 embedding model")
except Exception as e:
    print(f"‚ö†Ô∏è Error loading primary model: {e}")
    try:
        # Fall back to an even smaller model
        embedder = HuggingFaceEmbeddings(model_name="paraphrase-MiniLM-L3-v2")
        print("‚ö†Ô∏è Fallback to paraphrase-MiniLM-L3-v2 model")
    except Exception as e:
        print(f"‚ùå Critical error loading embedding models: {e}")
        # Create a dummy embedder that will warn but not crash the application
        from langchain_core.embeddings import Embeddings
        class DummyEmbedder(Embeddings):
            def embed_documents(self, texts):
                print("‚ö†Ô∏è Using dummy embedder - functionality limited")
                return [[0.0] * 384] * len(texts)
            def embed_query(self, text):
                return [0.0] * 384
        embedder = DummyEmbedder()

def build_faiss():
    """Reconstruct the FAISS index from JSON rules."""
    print(f"üîÑ Chargement des r√®gles depuis {JSON_RULES}")
    try:
        with open(JSON_RULES, encoding="utf-8") as f:
            rules = json.load(f)
        print(f"‚úÖ {len(rules)} r√®gles charg√©es")
        
        # Afficher un aper√ßu des premi√®res r√®gles
        for i, r in enumerate(rules[:3]):
            print(f"\nR√®gle {i+1}:")
            print(f"  Ann√©e: {r.get('ann√©e')}")
            print(f"  Taux: {r.get('taux')}")
            print(f"  Date application: {r.get('date_application')}")
            print(f"  B√©n√©ficiaire: {r.get('b√©n√©ficiaire')}")
            print(f"  Paragraphe: {r.get('paragraphe', '')[:50]}...")
            print(f"  Lien source: {r.get('lien_source', '')}")
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement du fichier JSON: {e}")
        print(f"Chemin actuel: {os.getcwd()}")
        print(f"Le fichier existe: {os.path.exists(JSON_RULES)}")
        return None
    
    docs = []
    for r in rules:
        # Extraction am√©lior√©e de l'ann√©e
        annee_str = r.get("ann√©e", "0")
        annee = 0
        if isinstance(annee_str, str):
            match = re.search(r'\d+', annee_str)
            if match:
                annee = int(match.group(0))
        
        # Contenu enrichi pour une meilleure recherche s√©mantique
        txt = (f"Cat√©gorie: {r.get('categorie', 'Non sp√©cifi√©')} | "
               f"Type: {r.get('type_de_revenu_ou_service', 'Non sp√©cifi√©')} | "
               f"Taux: {r.get('taux', 'N/A')} | "
               f"B√©n√©ficiaire: {r.get('b√©n√©ficiaire', 'Non sp√©cifi√©')} | "
               f"Application: {r.get('date_application', 'Non sp√©cifi√©e')}")
        
        docs.append(Document(
            page_content=txt,
            metadata={
                "annee": annee,
                "taux_num": r.get("taux_num"),
                "reference": r.get("r√©f√©rence_l√©gale", "Non sp√©cifi√©"),
                "source_file": r.get("source_file", "Non sp√©cifi√©"),
                "date_application": r.get("date_application", "Non sp√©cifi√©"),
                "paragraphe": r.get("paragraphe", "Non sp√©cifi√©"),
                "lien_source": r.get("lien_source", ""),
                "beneficiaire": r.get("b√©n√©ficiaire", "Non sp√©cifi√©"),
                "seuil": r.get("seuil", "Non sp√©cifi√©")
            }
        ))
    
    print(f"üîÑ Cr√©ation de l'index FAISS avec {len(docs)} documents")
    vect = FAISS.from_documents(docs, embedder)
    FAISS.save_local(vect, str(FAISS_DIR))
    print("‚úÖ Index FAISS reconstruit avec donn√©es enrichies.")
    return vect

def get_faiss_retriever():
    """Get a FAISS retriever, loading from disk or rebuilding if necessary."""
    try:
        vect = FAISS.load_local(
            str(FAISS_DIR),
            embeddings=embedder,
            allow_dangerous_deserialization=True
        )
        print("‚úÖ Index FAISS charg√© depuis le disque")
        return vect.as_retriever(search_kwargs={"k": 8})
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement de l'index FAISS: {e}")
        print("üîÑ Tentative de reconstruction de l'index...")
        vect = build_faiss()
        if vect is None:
            print("‚ùå Impossible de construire l'index FAISS. V√©rifiez le fichier JSON.")
            return None
        return vect.as_retriever(search_kwargs={"k": 8})